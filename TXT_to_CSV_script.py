#!/usr/bin/env python3
r'''
Interactive converter: txt to PostgreSQL‚Äëready CSV with auto-separator detection.
‚Äë –ó–∞–ø—É—Å–∫–∞–µ—Ç—Å—è –±–µ–∑ –∞—Ä–≥—É–º–µ–Ω—Ç–æ–≤.
‚Äë –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å –ø–æ –ø–µ—Ä–≤–æ–π —Å—Ç—Ä–æ–∫–µ (|, ;, tab, –∏ —Ç.–ø.).
‚Äë –°–ø—Ä–∞—à–∏–≤–∞–µ—Ç, –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç–µ –ª–∏ –∏–ª–∏ –≤–≤–æ–¥–∏—Ç–µ –≤—Ä—É—á–Ω—É—é (—Å –ø–æ–¥—Å–∫–∞–∑–∫–æ–π –ø—Ä–æ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ).
‚Äë –ü—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è ‚Üí \N (NULL –¥–ª—è PostgreSQL).
‚Äë –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ñ–∞–π–ª—ã –∏ URL, –ª–æ–≥ + –ø—Ä–æ–≥—Ä–µ—Å—Å.
'''

from __future__ import annotations

import csv, datetime as dt, itertools, logging, pathlib, re, shutil, sys, tempfile, urllib.request
from types import SimpleNamespace
from typing import List

try:
    from tqdm import tqdm
except ModuleNotFoundError:
    def tqdm(iterable=None, total=None, unit=None, unit_scale=False, desc=None):
        if iterable is None:
            return range(total or 0)
        return iterable

NULL = r'\N'
ENCODING_IN  = 'utf-8'
ENCODING_OUT = 'utf-8-sig'
COMMON_SEPARATORS = ['|', ',', ';', '\t']

def _safe_iso(raw: str) -> str:
    raw = raw.strip()
    try:
        d, m, y = raw.split('.')
        if len(y) == 4:
            return dt.date(int(y), int(m), int(d)).isoformat()
    except Exception:
        pass
    return NULL

def _ask(prompt: str, default: str | None = None) -> str:
    suffix = f' [{default}]' if default is not None else ''
    while True:
        val = input(f'{prompt}{suffix}: ').strip()
        if val:
            return val
        if default is not None:
            return default
        print('‚õî –ü—É—Å—Ç–æ–π –≤–≤–æ–¥ –Ω–µ–¥–æ–ø—É—Å—Ç–∏–º.')

def _select_file() -> str:
    while True:
        p = input('–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ .txt —Ñ–∞–π–ª—É, URL –∏–ª–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é: ').strip()
        if not p:
            print('‚õî –ü—É—Ç—å –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º.'); continue
        path = pathlib.Path(p)
        if path.is_file():
            return str(path.resolve())
        if path.is_dir():
            txt_files = sorted(f for f in path.iterdir() if f.suffix.lower() == '.txt')
            if not txt_files:
                print('‚õî –í –∫–∞—Ç–∞–ª–æ–≥–µ –Ω–µ—Ç .txt —Ñ–∞–π–ª–æ–≤.'); continue
            print('–ù–∞–π–¥–µ–Ω–Ω—ã–µ .txt —Ñ–∞–π–ª—ã:')
            for i, f in enumerate(txt_files, 1):
                print(f'{i}) {f.name}')
            idx = int(_ask('–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä —Ñ–∞–π–ª–∞', default='1'))
            return str(txt_files[idx-1].resolve())
        if p.startswith(('http://', 'https://')):
            return p
        print('‚õî –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä–æ–≤–∞—Ç—å –≤–≤–æ–¥.')

def _get_source(path_or_url: str) -> SimpleNamespace:
    p = pathlib.Path(path_or_url)
    if p.is_file():
        return SimpleNamespace(path=p.resolve(), cleanup=lambda: None)
    if path_or_url.startswith(('http://', 'https://')):
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix='.txt')
        logging.info('–°–∫–∞—á–∏–≤–∞—é %s ‚Ä¶', path_or_url)
        with urllib.request.urlopen(path_or_url) as resp, open(tmp.name, 'wb') as out:
            shutil.copyfileobj(resp, out)
        return SimpleNamespace(path=pathlib.Path(tmp.name), cleanup=lambda: pathlib.Path(tmp.name).unlink())
    sys.exit('‚õî –ù–µ –Ω–∞–π–¥–µ–Ω —Ñ–∞–π–ª –∏ –Ω–µ URL: ' + path_or_url)

def _guess_separator(first_line: str) -> str:
    counts = {sep: first_line.count(sep if sep != '\\t' else '\t') for sep in COMMON_SEPARATORS}
    best = max(counts.items(), key=lambda x: x[1])
    return best[0]

def _process(src: pathlib.Path, dst: pathlib.Path, sep_regex: re.Pattern[str], columns: List[str]) -> None:
    logging.info('–ß–∏—Ç–∞—é –∏–∑: %s', src)
    logging.info('–ü–∏—à—É  –≤ : %s', dst)
    total = src.stat().st_size
    date_idx = {i for i, c in enumerate(columns) if c.lower() in {'birthday', 'date'}}
    with src.open('r', encoding=ENCODING_IN, errors='ignore') as fin, dst.open('w', newline='', encoding=ENCODING_OUT) as fout:
        w = csv.writer(fout)
        w.writerow(columns)
        with tqdm(total=total, unit='B', unit_scale=True, desc='–û–±—Ä–∞–±–æ—Ç–∫–∞') as bar:
            for line in fin:
                bar.update(len(line.encode(ENCODING_IN)))
                fields = sep_regex.split(line.rstrip('\n'))
                fields = list(itertools.islice(fields + ['']*len(columns), len(columns)))
                fields = [f.strip() if f.strip() else NULL for f in fields]
                for idx in date_idx:
                    fields[idx] = _safe_iso(fields[idx])
                w.writerow(fields)
    logging.info('‚úì –ì–æ—Ç–æ–≤–æ. –ó–∞–ø–∏—Å–∞–Ω–æ %s', dst.name)

def main():
    logging.basicConfig(format='[%(levelname)s] %(message)s', level=logging.INFO)
    if len(sys.argv) > 2:
        sys.exit('–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python txt2pgcsv.py [—Ñ–∞–π–ª_–∏–ª–∏_URL]')

    path_or_url = sys.argv[1] if len(sys.argv) == 2 else _select_file()
    source = _get_source(path_or_url)

    # –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è
    with source.path.open('r', encoding=ENCODING_IN, errors='ignore') as f:
        first_line = f.readline()
    suggested = _guess_separator(first_line)
    human_suggest = {'|': r'\|', ',': ',', ';': ';', '\t': r'\t'}[suggested]
    print(f'üîç –ü—Ä–µ–¥–ø–æ–ª–∞–≥–∞–µ–º—ã–π —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å: {suggested!r}')
    print(f'–ï—Å–ª–∏ —Å–æ–≥–ª–∞—Å–Ω—ã ‚Äî –ø—Ä–æ—Å—Ç–æ –Ω–∞–∂–º–∏—Ç–µ Enter. –ï—Å–ª–∏ –¥—Ä—É–≥–æ–π ‚Äî –≤–≤–µ–¥–∏—Ç–µ –≤—Ä—É—á–Ω—É—é.')
    print('‚ö†Ô∏è  –ï—Å–ª–∏ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ | –∏–ª–∏ –¥—Ä—É–≥–æ–π —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª ‚Äî —ç–∫—Ä–∞–Ω–∏—Ä—É–π—Ç–µ –µ–≥–æ (–Ω–∞–ø—Ä–∏–º–µ—Ä: \\| –∏–ª–∏ \\t)')
    sep_raw = _ask('–í–≤–µ–¥–∏—Ç–µ —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å (regex)', default=human_suggest)
    sep_regex = re.compile(rf'\s*{sep_raw}\s*')

    cols_raw = _ask('–í–≤–µ–¥–∏—Ç–µ –Ω–∞–∑–≤–∞–Ω–∏—è –∫–æ–ª–æ–Ω–æ–∫ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é (–≤ –ø–æ—Ä—è–¥–∫–µ —Å–ª–µ–¥–æ–≤–∞–Ω–∏—è)')
    columns = [c.strip() for c in cols_raw.split(',') if c.strip()]
    if not columns:
        sys.exit('‚õî –ù–µ –ø–æ–ª—É—á–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–π –∫–æ–ª–æ–Ω–∫–∏ ‚Äî –∑–∞–≤–µ—Ä—à–∞—é.')

    dst = source.path.with_name(f'{source.path.stem}_pg.csv')
    try:
        _process(source.path, dst, sep_regex, columns)
    finally:
        source.cleanup()

if __name__ == '__main__':
    main()